x Implement and test cyclic LR scheduling

x Implement and test wCE + Dice loss

x Implement option to save model output as foreground probabilities in inference
x Enable compression while writing

- Simplify the config system:
    - State kwargs as they are in the config files ('_' rather than '-')

- Implement validation metrics:
    x Dice and Jaccard for now. 
    - Then Surface Dice


- Improve WandB logging:
    x Different logging steps for training and validation
    x Log system-related stuff 
    - Log richer info - prediction, etc.


- Efficiency improvement:
    - torch.cuda.empty_cache() -- read more about this
    - Option for distributed training: See torch DataParallel for now. Later move on to using torch DistributedDataParallel 

- Integrate enable_distributed option of the Trainer and Infer into the config system